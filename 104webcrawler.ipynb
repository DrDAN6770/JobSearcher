{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Moduel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, time, requests, random\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同步版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同步版本\n",
    "class Job_search104():\n",
    "    current_date = datetime.now().date()\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    search_url = 'https://www.104.com.tw/jobs/search/?'\n",
    "    def __init__(self, filter_params, key_word, page = 15):\n",
    "        self.filter_params = filter_params\n",
    "        self.key_word = key_word\n",
    "        self.page = page\n",
    "           \n",
    "    def search_job(self):\n",
    "        url = requests.get(self.search_url, self.filter_params, headers=self.headers).url\n",
    "        option = Options()\n",
    "        option.add_experimental_option('excludeSwitches', ['enable-automation']) # 開發者模式。可以避開某些防爬機制，有開有保佑\n",
    "        option.add_argument('--headless') # 無頭模式，開發完成之後再使用，可以完全背景執行，有機會變快\n",
    "        option.add_argument(\"--disable-gpu\") # 禁用GPU加速，有些情況下需要設置這個參數\n",
    "        driver = webdriver.Chrome(options=option)\n",
    "        driver.get(url)\n",
    "\n",
    "        element = driver.find_element(By.XPATH,'//*[@id=\"js-job-header\"]/div[1]/label[1]/select/option[1]')\n",
    "        total_page = int(re.sub(r'\\D', '', element.text.split('/')[-1]))\n",
    "        print(f'Total_page = {total_page}')\n",
    "        # 滾頁面\n",
    "        scroll_times = self.page\n",
    "        for _ in range(scroll_times):\n",
    "            driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "            time.sleep(2)\n",
    "\n",
    "        # 自動加載結束後要自行點選載入(15以後)\n",
    "        # 使用CSS選擇器定位最後一個按鈕並點擊\n",
    "        if total_page >= 15:\n",
    "            k = 1\n",
    "            while True:\n",
    "                try:\n",
    "                    button_element = WebDriverWait(driver, 3).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, '#js-job-content > div:last-child > button'))\n",
    "                    )\n",
    "                    print(f'手動載入第{15 + k}頁')\n",
    "                    button_element.click()\n",
    "                    k += 1\n",
    "                    if k == 86 or k == total_page - 14 :\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(\"發生未知錯誤：\", e)\n",
    "                    break\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        print(f'共{len(soup.find_all(\"a\",class_=\"js-job-link\"))}筆資料')\n",
    "        driver.quit()\n",
    "        return soup\n",
    "    \n",
    "    def job_details(self, url):\n",
    "        option = Options()\n",
    "        option.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "        driver = webdriver.Chrome(options=option)\n",
    "        driver.maximize_window()\n",
    "        wait = WebDriverWait(driver, 3)\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            element = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'job-header__title')))\n",
    "        except Exception as e:\n",
    "            print('Driver Error')\n",
    "        page_source = driver.page_source\n",
    "        driver.quit()\n",
    "        return page_source\n",
    "    \n",
    "    def update_date(self, soup) -> str:\n",
    "        update_date = soup.find(\"div\", class_=\"job-header__title\")\n",
    "        return update_date.find('span').text.strip().replace('更新','') if update_date else None\n",
    "    \n",
    "    def company(self, soup) -> str:\n",
    "        name = soup.find(\"div\", class_=\"mt-3\")\n",
    "        return name.select_one('div > a').text.strip() if name else None\n",
    "    \n",
    "    def jd_info(self, soup) -> dict:\n",
    "        result = {}\n",
    "        JD = soup.find('div', class_='job-description-table row')\n",
    "        if JD:\n",
    "            jd_items = JD.find_all('div', recursive=False)\n",
    "            if jd_items:\n",
    "                    result = {\n",
    "                                '工作內容': jd_items[0].find('p').text,\n",
    "                                '職務類別': ', '.join(i.text for i in jd_items[1].find_all('u')),\n",
    "                                '工作待遇': jd_items[2].find_all('div', recursive=False)[-1].text.strip(),\n",
    "                                '工作性質': jd_items[3].find_all('div')[-1].text.strip(),\n",
    "                                '上班地點': jd_items[4].find_all('div')[-1].text.strip(),\n",
    "                                '管理責任': jd_items[6].find_all('div')[-1].text.strip(),\n",
    "                                '出差外派': jd_items[7].find_all('div')[-1].text.strip(),\n",
    "                                '上班時段': jd_items[8].find_all('div')[-1].text.strip(),\n",
    "                                '休假制度': jd_items[9].find_all('div')[-1].text.strip(),\n",
    "                                '可上班日': jd_items[10].find_all('div')[-1].text.strip(),\n",
    "                                '需求人數': jd_items[11].find_all('div')[-1].text.strip()\n",
    "                            }\n",
    "        return result\n",
    "    \n",
    "    def jr_info(self, soup) -> dict:\n",
    "        result = {}\n",
    "        JR = soup.find('div', class_= 'job-requirement-table row')\n",
    "        JRO = soup.find('div', class_= 'job-requirement col opened')\n",
    "        if JR:\n",
    "            jr_items = JR.find_all('div', recursive=False)\n",
    "            if jr_items:\n",
    "                result = {\n",
    "                    '工作經歷' : jr_items[0].find_all('div')[-1].text.strip(),\n",
    "                    '學歷要求' : jr_items[1].find_all('div')[-1].text.strip(),\n",
    "                    '科系要求' : jr_items[2].find_all('div')[-1].text.strip(),\n",
    "                    '語文條件' : jr_items[3].find_all('div')[-1].text.strip(),\n",
    "                    '擅長工具' : ', '.join(i.text for i in jr_items[4].find_all('u')),\n",
    "                    '工作技能' : jr_items[5].find_all('div')[-1].text.strip(),\n",
    "                    '其他要求' : JRO.find_all('div')[-1].text.strip() if JRO else '無'\n",
    "                }\n",
    "        return result\n",
    "    \n",
    "    def main(self, Job_list : list, DF):\n",
    "        for idx, item in enumerate(Job_list):\n",
    "            title = item['title']\n",
    "            lower_title = title.lower()\n",
    "            if not re.search(self.key_word, lower_title):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                Job_link = f\"https:{item['href']}\"\n",
    "                response = requests.get(Job_link)\n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "                \n",
    "                Data = {\n",
    "                        '更新日期' : [self.update_date(soup)],\n",
    "                        '職缺名稱' : [title],\n",
    "                        '公司名稱' : [self.company(soup)],\n",
    "                        '連結' : [Job_link]\n",
    "                }\n",
    "                Data.update(self.jd_info(soup))\n",
    "                Data.update(self.jr_info(soup))\n",
    "                df = pd.DataFrame(Data, columns=['更新日期', '職缺名稱', '公司名稱', '工作內容', '職務類別', '工作待遇',\n",
    "                                                    '工作性質', '上班地點', '管理責任', '出差外派', '上班時段', '休假制度',\n",
    "                                                    '可上班日', '需求人數', '工作經歷', '學歷要求', '科系要求', '語文條件',\n",
    "                                                    '擅長工具', '工作技能', '其他要求', '連結'])\n",
    "                DF = pd.concat([DF, df], ignore_index=True)\n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    print(f\"success {idx+1} !\")\n",
    "                time.sleep(random.uniform(0.4, 0.7)) # 0.4 ~ 0.7 second\n",
    "            except Exception as e:\n",
    "                print(f\"{idx} 發生錯誤\", e)\n",
    "                DF.to_csv(f\"JBLIST_{self.current_date}.csv\", sep='|', index=False)\n",
    "                \n",
    "        DF.to_csv(f\"JBLIST_{self.current_date}.csv\", sep='|', index=False)\n",
    "        return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 建立物件\n",
    "JBDF = pd.DataFrame()\n",
    "\n",
    "# 搜尋關鍵字 與 過濾非相關職缺關鍵字\n",
    "keywords_pattern = r'工程|資料|python|data|數據'\n",
    "filter_params = {\n",
    "    'ro' : 1, # 1 全職\n",
    "    'keyword' : '資料工程',\n",
    "    'area' : '6001002000,6001001000,6001006000,C6001008000',  # 6001001000 台北市 6001002000 新北 6001006000 新竹縣市 6001008000 台中市\n",
    "    'isnew' : 0, # 0:本日 3:3天內 7:1週內 14 30\n",
    "    'jobexp' : '1,3', # 工作經驗1年以下 + 1-3年\n",
    "    'mode' : 'l', # 列表模式(比較多筆資料)\n",
    "    'order' : 16 # 照日期排序\n",
    "}\n",
    "\n",
    "JBS = Job_search104(filter_params, keywords_pattern)\n",
    "while True:\n",
    "    try:\n",
    "        soup = JBS.search_job()\n",
    "        break\n",
    "    except:\n",
    "        print('執行錯誤, retry')\n",
    "Job_list = soup.find_all(\"a\",class_=\"js-job-link\")\n",
    "\n",
    "res = JBS.main(Job_list, JBDF)\n",
    "print(\"花費：\" + str(time.time() - start_time) + \"秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非同步版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import grequests # 看起要在.py才能用\n",
    "from aiohttp import ClientSession, TCPConnector\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eJob_search104():\n",
    "    current_date = datetime.now().date()\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    search_url = 'https://www.104.com.tw/jobs/search/?'\n",
    "    def __init__(self, filter_params, key_word, page = 15):\n",
    "        self.filter_params = filter_params\n",
    "        self.key_word = key_word\n",
    "        self.page = page\n",
    "           \n",
    "    def search_job(self):\n",
    "        url = requests.get(self.search_url, self.filter_params, headers=self.headers).url\n",
    "        print(url)\n",
    "        option = Options()\n",
    "        option.add_experimental_option('excludeSwitches', ['enable-automation']) # 開發者模式。可以避開某些防爬機制，有開有保佑\n",
    "        option.add_argument('--headless') # 無頭模式，開發完成之後再使用，可以完全背景執行，有機會變快\n",
    "        option.add_argument(\"--disable-gpu\") # 禁用GPU加速，有些情況下需要設置這個參數\n",
    "        driver = webdriver.Chrome(options=option)\n",
    "        driver.get(url)\n",
    "\n",
    "        element = driver.find_element(By.XPATH,'//*[@id=\"js-job-header\"]/div[1]/label[1]/select/option[1]')\n",
    "        total_page = int(re.sub(r'\\D', '', element.text.split('/')[-1]))\n",
    "        print(f'Total_page = {total_page}')\n",
    "        # 滾頁面\n",
    "        scroll_times = self.page\n",
    "        for _ in range(scroll_times):\n",
    "            driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "            time.sleep(2)\n",
    "\n",
    "        # 自動加載結束後要自行點選載入(15以後)\n",
    "        # 使用CSS選擇器定位最後一個按鈕並點擊\n",
    "        if total_page >= 15:\n",
    "            k = 1\n",
    "            while True:\n",
    "                try:\n",
    "                    button_element = WebDriverWait(driver, 3).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, '#js-job-content > div:last-child > button'))\n",
    "                    )\n",
    "                    print(f'手動載入第{15 + k}頁')\n",
    "                    button_element.click()\n",
    "                    k += 1\n",
    "                    if k == 86 or k == total_page - 14 :\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(\"發生未知錯誤：\", e)\n",
    "                    break\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        raw_Job_list = soup.find_all(\"a\",class_=\"js-job-link\")\n",
    "        print(f'共{len(raw_Job_list)}筆資料')\n",
    "        driver.quit()\n",
    "        return raw_Job_list\n",
    "    \n",
    "    def filter_job(self, raw_Job_list:list):\n",
    "        filter_job_list = [i for i in raw_Job_list if re.search(self.key_word, i['title'].lower())]\n",
    "        print(f'過濾完有{len(filter_job_list)}筆')\n",
    "        return filter_job_list\n",
    "    \n",
    "    def update_date(self, soup) -> str:\n",
    "        update_date = soup.find(\"div\", class_=\"job-header__title\")\n",
    "        return update_date.find('span').text.strip().replace('更新','') if update_date else None\n",
    "    \n",
    "    def company(self, soup) -> str:\n",
    "        name = soup.find(\"div\", class_=\"mt-3\")\n",
    "        return name.select_one('div > a').text.strip() if name else None\n",
    "    \n",
    "    def jd_info(self, soup) -> dict:\n",
    "        result = {}\n",
    "        JD = soup.find('div', class_='job-description-table row')\n",
    "        if JD:\n",
    "            jd_items = JD.find_all('div', recursive=False)\n",
    "            if jd_items:\n",
    "                    result = {\n",
    "                                '工作內容': jd_items[0].find('p').text,\n",
    "                                '職務類別': ', '.join(i.text for i in jd_items[1].find_all('u')),\n",
    "                                '工作待遇': jd_items[2].find_all('div', recursive=False)[-1].text.strip(),\n",
    "                                '工作性質': jd_items[3].find_all('div')[-1].text.strip(),\n",
    "                                '上班地點': jd_items[4].find_all('div')[-1].text.strip(),\n",
    "                                '管理責任': jd_items[6].find_all('div')[-1].text.strip(),\n",
    "                                '出差外派': jd_items[7].find_all('div')[-1].text.strip(),\n",
    "                                '上班時段': jd_items[8].find_all('div')[-1].text.strip(),\n",
    "                                '休假制度': jd_items[9].find_all('div')[-1].text.strip(),\n",
    "                                '可上班日': jd_items[10].find_all('div')[-1].text.strip(),\n",
    "                                '需求人數': jd_items[11].find_all('div')[-1].text.strip()\n",
    "                            }\n",
    "        return result\n",
    "    \n",
    "    def jr_info(self, soup) -> dict:\n",
    "        result = {}\n",
    "        JR = soup.find('div', class_= 'job-requirement-table row')\n",
    "        JRO = soup.find('div', class_= 'job-requirement col opened')\n",
    "        if JR:\n",
    "            jr_items = JR.find_all('div', recursive=False)\n",
    "            if jr_items:\n",
    "                result = {\n",
    "                    '工作經歷' : jr_items[0].find_all('div')[-1].text.strip(),\n",
    "                    '學歷要求' : jr_items[1].find_all('div')[-1].text.strip(),\n",
    "                    '科系要求' : jr_items[2].find_all('div')[-1].text.strip(),\n",
    "                    '語文條件' : jr_items[3].find_all('div')[-1].text.strip(),\n",
    "                    '擅長工具' : ', '.join(i.text for i in jr_items[4].find_all('u')),\n",
    "                    '工作技能' : jr_items[5].find_all('div')[-1].text.strip(),\n",
    "                    '其他要求' : JRO.find_all('div')[-1].text.strip() if JRO else '無'\n",
    "                }\n",
    "        return result\n",
    "    \n",
    "    async def fetch(self, session, url):\n",
    "        async with session.get(url, headers = {'User-Agent':'GoogleBot'}) as response:\n",
    "            return await response.text()\n",
    "\n",
    "    async def get_job_info(self, item):\n",
    "        try:\n",
    "            title = item['title']\n",
    "            Job_link = f\"https:{item['href']}\"\n",
    "            connector = TCPConnector(limit=10)\n",
    "            async with ClientSession(connector=connector) as session:\n",
    "                html = await self.fetch(session, Job_link)\n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            Data = {\n",
    "                '更新日期': [self.update_date(soup)],\n",
    "                '職缺名稱': [title],\n",
    "                '公司名稱': [self.company(soup)],\n",
    "                '連結': [Job_link]\n",
    "            }\n",
    "            Data.update(self.jd_info(soup))\n",
    "            Data.update(self.jr_info(soup))\n",
    "            df = pd.DataFrame(Data, columns=['更新日期', '職缺名稱', '公司名稱', '工作內容', '職務類別', '工作待遇',\n",
    "                                            '工作性質', '上班地點', '管理責任', '出差外派', '上班時段', '休假制度',\n",
    "                                            '可上班日', '需求人數', '工作經歷', '學歷要求', '科系要求', '語文條件',\n",
    "                                            '擅長工具', '工作技能', '其他要求', '連結'])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(\"發生錯誤\", e)\n",
    "            return None\n",
    "\n",
    "    async def scrape(self, Job_list):\n",
    "        tasks = []\n",
    "        semaphore = asyncio.Semaphore(10)  # Limit concurrent requests to 10\n",
    "\n",
    "        for item in Job_list:\n",
    "            async with semaphore:\n",
    "                task = asyncio.ensure_future(self.get_job_info(item))\n",
    "                tasks.append(task)\n",
    "\n",
    "        return await asyncio.gather(*tasks)\n",
    "    \n",
    "    def main(self, Job_list: list, DF):\n",
    "        print(len(Job_list))\n",
    "        batch_size = 30\n",
    "        num_batches = (len(Job_list) + batch_size - 1) // batch_size\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min((batch_idx + 1) * batch_size, len(Job_list))\n",
    "            Job_list_batch = Job_list[start_idx:end_idx]\n",
    "            loop = asyncio.get_event_loop()\n",
    "            results = loop.run_until_complete(self.scrape(Job_list_batch))\n",
    "            # loop.close()\n",
    "\n",
    "            for df in results:\n",
    "                if df is not None:\n",
    "                    DF = pd.concat([DF, df], ignore_index=True)\n",
    "\n",
    "        DF.to_csv(f\"JBLIST_{self.current_date}.csv\", sep='|', index=False)\n",
    "        return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 過濾關鍵字以外的職缺\n",
    "keywords_pattern = r'工程|資料|python|data|數據'\n",
    "\n",
    "# 搜尋關鍵字\n",
    "filter_params = {\n",
    "    'ro' : 1, # 1 全職\n",
    "    'keyword' : '資料工程',\n",
    "    'area' : '6001002000,6001001000,6001006000,C6001008000',  # 6001001000 台北市 6001002000 新北 6001006000 新竹縣市 6001008000 台中市\n",
    "    'isnew' : 3, # 0:本日 3:3天內 7:1週內 14 30\n",
    "    'jobexp' : '1,3', # 工作經驗1年以下 + 1-3年\n",
    "    'mode' : 'l', # 列表模式(比較多筆資料)\n",
    "    'order' : 16 # 照日期排序\n",
    "}\n",
    "\n",
    "# 建立物件\n",
    "DF = pd.DataFrame()\n",
    "EJS = eJob_search104(filter_params, keywords_pattern)\n",
    "while True:\n",
    "    try:\n",
    "        raw_Job_list = EJS.search_job()\n",
    "        break\n",
    "    except:\n",
    "        print('執行錯誤, retry')\n",
    "Job_list = EJS.filter_job(raw_Job_list)\n",
    "result_df = EJS.main(Job_list, DF)\n",
    "print(f\"花費 {time.time() - start_time} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data\n",
    "result_df[result_df.isnull().any(axis=1)]\n",
    "clean_df = result_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().date()\n",
    "clean_df.to_csv(f\"JBLIST_{current_date}.csv\", sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>更新日期</th>\n",
       "      <th>職缺名稱</th>\n",
       "      <th>公司名稱</th>\n",
       "      <th>工作內容</th>\n",
       "      <th>職務類別</th>\n",
       "      <th>工作待遇</th>\n",
       "      <th>工作性質</th>\n",
       "      <th>上班地點</th>\n",
       "      <th>管理責任</th>\n",
       "      <th>出差外派</th>\n",
       "      <th>...</th>\n",
       "      <th>可上班日</th>\n",
       "      <th>需求人數</th>\n",
       "      <th>工作經歷</th>\n",
       "      <th>學歷要求</th>\n",
       "      <th>科系要求</th>\n",
       "      <th>語文條件</th>\n",
       "      <th>擅長工具</th>\n",
       "      <th>工作技能</th>\n",
       "      <th>其他要求</th>\n",
       "      <th>連結</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/22</td>\n",
       "      <td>網路系統工程師</td>\n",
       "      <td>邦鉑科技股份有限公司</td>\n",
       "      <td>公司擴編需求，需要相關技能的你！\\n\\n因應公司業務展望，提供優渥的獎金與福利制度，期待加入...</td>\n",
       "      <td>網路管理工程師, 資訊設備管制人員, 產品售後技術服務</td>\n",
       "      <td>月薪40,000~60,000元  （固定或變動薪資因個人資歷或績效而異）</td>\n",
       "      <td>全職</td>\n",
       "      <td>台北市內湖區新明路159號6樓</td>\n",
       "      <td>不需負擔管理責任</td>\n",
       "      <td>需出差，一年累積時間約一個月以下</td>\n",
       "      <td>...</td>\n",
       "      <td>兩週內</td>\n",
       "      <td>3~4人</td>\n",
       "      <td>1年以上</td>\n",
       "      <td>專科、大學</td>\n",
       "      <td>不拘</td>\n",
       "      <td>不拘</td>\n",
       "      <td>Windows XP, Vmware, Cisco, Firewall, Juniper, ...</td>\n",
       "      <td>伺服器網站管理維護、資訊設備環境設定、系統維護操作、資料庫系統管理維護、系統架構規劃與維護、...</td>\n",
       "      <td>無</td>\n",
       "      <td>https://www.104.com.tw/job/7hryf?jobsource=hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/06</td>\n",
       "      <td>【派遣至台灣知名壽險公司】Java 工程師</td>\n",
       "      <td>博策致遠科技有限公司</td>\n",
       "      <td>1. 開發及維護 Java 企業級系統的銷售模組\\n\\n2. 優化系統的用戶體驗、資安及效能...</td>\n",
       "      <td>軟體設計工程師, 系統維護／操作人員, 資料庫管理人員</td>\n",
       "      <td>待遇面議  （經常性薪資達 4 萬元或以上）</td>\n",
       "      <td>全職</td>\n",
       "      <td>台北市信義區莊敬路168號  (距捷運台北101/世貿站約220公尺)</td>\n",
       "      <td>不需負擔管理責任</td>\n",
       "      <td>無需出差外派</td>\n",
       "      <td>...</td>\n",
       "      <td>一個月內</td>\n",
       "      <td>2~3人</td>\n",
       "      <td>不拘</td>\n",
       "      <td>大學以上</td>\n",
       "      <td>不拘</td>\n",
       "      <td>不拘</td>\n",
       "      <td>Java, Spring, jQuery, SAP</td>\n",
       "      <td>作業系統基本操作、系統架構規劃、軟體工程系統開發、軟體程式設計、網路程式設計、資料庫系統管理...</td>\n",
       "      <td>1. 熟悉JAVA之應用程式開發\\n\\n2. 具備進修程式語言之意願\\n\\n3. 需具備與使...</td>\n",
       "      <td>https://www.104.com.tw/job/81orv?jobsource=jol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/29</td>\n",
       "      <td>【派遣至台灣知名壽險公司】SAP ABAP初階工程師</td>\n",
       "      <td>博策致遠科技有限公司</td>\n",
       "      <td>1. SAP CRM / Gateway 系統之開發與維護\\n\\n2. SAP CRM / ...</td>\n",
       "      <td>軟體設計工程師, 系統維護／操作人員, 資料庫管理人員</td>\n",
       "      <td>月薪30,000~45,000元  （固定或變動薪資因個人資歷或績效而異）</td>\n",
       "      <td>全職</td>\n",
       "      <td>台北市信義區莊敬路168號  (距捷運台北101/世貿站約220公尺)</td>\n",
       "      <td>不需負擔管理責任</td>\n",
       "      <td>無需出差外派</td>\n",
       "      <td>...</td>\n",
       "      <td>一個月內</td>\n",
       "      <td>2~3人</td>\n",
       "      <td>不拘</td>\n",
       "      <td>大學以上</td>\n",
       "      <td>不拘</td>\n",
       "      <td>不拘</td>\n",
       "      <td>Java, Spring, jQuery, SAP</td>\n",
       "      <td>作業系統基本操作、系統架構規劃、軟體工程系統開發、軟體程式設計、網路程式設計、資料庫系統管理...</td>\n",
       "      <td>無</td>\n",
       "      <td>https://www.104.com.tw/job/81g40?jobsource=jol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    更新日期                        職缺名稱        公司名稱  \\\n",
       "0  07/22                     網路系統工程師  邦鉑科技股份有限公司   \n",
       "1  07/06       【派遣至台灣知名壽險公司】Java 工程師  博策致遠科技有限公司   \n",
       "2  06/29  【派遣至台灣知名壽險公司】SAP ABAP初階工程師  博策致遠科技有限公司   \n",
       "\n",
       "                                                工作內容  \\\n",
       "0  公司擴編需求，需要相關技能的你！\\n\\n因應公司業務展望，提供優渥的獎金與福利制度，期待加入...   \n",
       "1  1. 開發及維護 Java 企業級系統的銷售模組\\n\\n2. 優化系統的用戶體驗、資安及效能...   \n",
       "2  1. SAP CRM / Gateway 系統之開發與維護\\n\\n2. SAP CRM / ...   \n",
       "\n",
       "                          職務類別                                   工作待遇 工作性質  \\\n",
       "0  網路管理工程師, 資訊設備管制人員, 產品售後技術服務  月薪40,000~60,000元  （固定或變動薪資因個人資歷或績效而異）   全職   \n",
       "1  軟體設計工程師, 系統維護／操作人員, 資料庫管理人員                 待遇面議  （經常性薪資達 4 萬元或以上）   全職   \n",
       "2  軟體設計工程師, 系統維護／操作人員, 資料庫管理人員  月薪30,000~45,000元  （固定或變動薪資因個人資歷或績效而異）   全職   \n",
       "\n",
       "                                  上班地點      管理責任              出差外派  ...  可上班日  \\\n",
       "0                      台北市內湖區新明路159號6樓  不需負擔管理責任  需出差，一年累積時間約一個月以下  ...   兩週內   \n",
       "1  台北市信義區莊敬路168號  (距捷運台北101/世貿站約220公尺)  不需負擔管理責任            無需出差外派  ...  一個月內   \n",
       "2  台北市信義區莊敬路168號  (距捷運台北101/世貿站約220公尺)  不需負擔管理責任            無需出差外派  ...  一個月內   \n",
       "\n",
       "   需求人數  工作經歷   學歷要求 科系要求 語文條件  \\\n",
       "0  3~4人  1年以上  專科、大學   不拘   不拘   \n",
       "1  2~3人    不拘   大學以上   不拘   不拘   \n",
       "2  2~3人    不拘   大學以上   不拘   不拘   \n",
       "\n",
       "                                                擅長工具  \\\n",
       "0  Windows XP, Vmware, Cisco, Firewall, Juniper, ...   \n",
       "1                          Java, Spring, jQuery, SAP   \n",
       "2                          Java, Spring, jQuery, SAP   \n",
       "\n",
       "                                                工作技能  \\\n",
       "0  伺服器網站管理維護、資訊設備環境設定、系統維護操作、資料庫系統管理維護、系統架構規劃與維護、...   \n",
       "1  作業系統基本操作、系統架構規劃、軟體工程系統開發、軟體程式設計、網路程式設計、資料庫系統管理...   \n",
       "2  作業系統基本操作、系統架構規劃、軟體工程系統開發、軟體程式設計、網路程式設計、資料庫系統管理...   \n",
       "\n",
       "                                                其他要求  \\\n",
       "0                                                  無   \n",
       "1  1. 熟悉JAVA之應用程式開發\\n\\n2. 具備進修程式語言之意願\\n\\n3. 需具備與使...   \n",
       "2                                                  無   \n",
       "\n",
       "                                                  連結  \n",
       "0  https://www.104.com.tw/job/7hryf?jobsource=hot...  \n",
       "1  https://www.104.com.tw/job/81orv?jobsource=jol...  \n",
       "2  https://www.104.com.tw/job/81g40?jobsource=jol...  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('JBLIST_2023-07-27.csv',sep ='|')\n",
    "d.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Web_Crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
